{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "SEED=200\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(x, column):\n",
    "    diff = max(column) - min(column)\n",
    "    return (x - min(column)) / diff\n",
    "\n",
    "def rescale(df, columns):\n",
    "    \"\"\"\n",
    "    df: dataframe com o dataset\n",
    "    columns: nomes das colunas que devem ser reescaladas\n",
    "    retorna o dataset reescalado\n",
    "    \"\"\"    \n",
    "    # for each column\n",
    "    for c in columns:\n",
    "        # rescale each value (row)\n",
    "        df[c] = df.apply(lambda row: minmax(row[c], df[c]), axis=1)\n",
    "    return df\n",
    "\n",
    "def line_equation(theta, x):\n",
    "    \"\"\"Equação da reta\n",
    "    theta (nparray): Numpy array com os coeficientes da equação da reta (e.g. np.array([0.1, 0.3]))\n",
    "    x (float): Valor float do eixo x\n",
    "    retorna o valor do eixo y resultante \n",
    "    \"\"\"\n",
    "    return theta[0] + theta[1] * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A equação normal encontra os parâmetros ideais de forma analítica. A equação pode ser encontrada ao setar as derivadas parciais da função de custo para 0.\n",
    "\n",
    "$$\\Theta = (X^tX)^{-1}X^tf(x)$$\n",
    "\n",
    "Muitas vezes pode não haver inversa. Quando isso acontece pode-se realizar aproximações numéricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(df):\n",
    "    \"\"\"Equação normal que calcula o resultado final ideal para os pesos\n",
    "    df (dataframe): Pandas dataframe com os dados\n",
    "    retorna um numpy array com os valores de theta resultantes da equação. Podem ser Nulos\n",
    "    \"\"\"\n",
    "    return (1/df.T.dot(df)).dot(df.T).dot(Y).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro passo é abrir os dados.\n",
    "#### Nesse caso os dados estão em train_reg.csv. Um subset com os 200 primeiros elementos é retirado do csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Nao alterar\"\"\"\n",
    "df = pd.read_csv('../regression_dataset/train_reg.csv')\n",
    "df = rescale(df, columns=df.columns[:])\n",
    "\n",
    "# Try the normal equation for the first 200\n",
    "subset = df.iloc[0:200]\n",
    "X, Y = subset.iloc[:,0], subset.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Em seguida deve ser utilizada a equação normal para encontrar os valores ideais de theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Nao alterar\"\"\"\n",
    "theta = normal_equation(subset)\n",
    "\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, Y)\n",
    "\n",
    "line = [0] * 2\n",
    "line[0] = line_equation(theta, X.min())\n",
    "line[1] = line_equation(theta, X.max())\n",
    "\n",
    "drawn, = ax.plot((X.min(), X.max()), (line[0], line[1]), c='r')\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A segunda abordagem é utilizando o Gradiente Descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_step(df, theta, learning_rate=1e-5):\n",
    "    \"\"\"Realiza um passo do gradiente descendente\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): Conjunto de dados (X, Y) => 699x2\n",
    "        theta (nparray): Numpy Array com os valores de theta na iteração anterior do treinamento\n",
    "        learning_rate (float): Taxa de aprendizado alpha\n",
    "        \n",
    "    Returns:\n",
    "        nparray: um conjunto novo de Theta\n",
    "        float: erro => cost function...\n",
    "    \"\"\"\n",
    "    df_size = X.size\n",
    "    df_X = X\n",
    "    df_Y = Y\n",
    "\n",
    "    y_hat_array = theta[0] + (theta[1] * df_X)\n",
    "\n",
    "    cost = np.sum((y_hat_array - df_Y) ** 2) / (2 * df_size)\n",
    "\n",
    "    t0 = theta[0] - learning_rate * (1/df_size) * np.sum(y_hat_array - df_Y)\n",
    "    t1 = theta[1] - learning_rate * (1/df_size) * np.sum((y_hat_array - df_Y) * df_X)\n",
    "    \n",
    "    new_theta = np.array([t0, t1])\n",
    "\n",
    "    return new_theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Nao alterar\"\"\"\n",
    "# Cria o grafico e atualiza os pesos\n",
    "fig = plt.figure(tight_layout=True, figsize=(12,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, Y)\n",
    "\n",
    "# Inicializa os pesos (theta) e plota a primeira reta do grafico\n",
    "theta = [3, 4]\n",
    "line = [0] * 2\n",
    "line[0] = line_equation(theta, X.min())\n",
    "line[1] = line_equation(theta, X.max())\n",
    "drawn, = ax.plot((X.min(), X.max()), (line[0], line[1]), c='r')\n",
    "ax.set_ylim((0, 1.5))\n",
    "\n",
    "GRADIENT_DESCENT_ITERATIONS = 50\n",
    "t = tqdm(range(0, GRADIENT_DESCENT_ITERATIONS))\n",
    "for it in t:\n",
    "    theta, error = gradient_descent_step(df, theta, learning_rate=0.5)\n",
    "    t.set_description(\"Error: %.6s     \" % error)\n",
    "    \n",
    "    # Atualiza o grafico\n",
    "    line[0] = line_equation(theta, X.min())\n",
    "    #print(line[0])\n",
    "    line[1] = line_equation(theta, X.max())\n",
    "    drawn.set_xdata((X.min(), X.max()))\n",
    "    drawn.set_ydata((line[0], line[1]))\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar o dataset iris\n",
    "### Escolher entre implementar rescale ou normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Rescale and normalize functions: implement the missing functions\"\"\"\n",
    "def rescale(df, columns, maximum=None, minimum=None):\n",
    "    \"\"\"\n",
    "    df: a dataframe with the dataset\n",
    "    columns: the column names from the dataframe that should be rescaled\n",
    "    maximum: a dictionary with the maximum value with each key representing a column\n",
    "    minimum: a dictionary with the minimum value with each key representing a column\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"implementar rescale\")\n",
    "\n",
    "def normalize(df, columns, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    df: a dataframe with the dataset\n",
    "    columns: the column names from the dataframe that should be normalized\n",
    "    mean: a dictionary with the mean value with each key representing a column\n",
    "    std: a dictionary with the standard deviation value with each key representing a column\n",
    "    \"\"\"\n",
    "\n",
    "    # normalize each defined column \n",
    "    for c in columns:\n",
    "        mean_c = mean[c] if mean and mean[c] else df.get(c).mean()\n",
    "        std_c = std[c] if std and std[c] else df.get(c).std()\n",
    "        df.get(c).apply(lambda x: ((x - mean_c) / std_c))\n",
    "    return df, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Carrega o iris e deixa somente os dois primeiros atributos, além do atributo alvo. Nao alterar esta celula\"\"\"\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "df_full = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                       columns=iris['feature_names'] + ['target'])\n",
    "df_full = df_full[df_full.target != 2.]\n",
    "df_full = df_full.loc[:,[\"sepal length (cm)\", \"sepal width (cm)\", \"target\"]]\n",
    "\n",
    "def get_train_test_inds(y, train_proportion=0.7):\n",
    "    \"\"\"\n",
    "    y: coluna do atributo alvo\n",
    "    retorna os indices de treino e teste estratificados pela classe\n",
    "    \"\"\"\n",
    "    y=np.array(y)\n",
    "    train_inds = np.zeros(len(y),dtype=bool)\n",
    "    test_inds = np.zeros(len(y),dtype=bool)\n",
    "    values = np.unique(y)\n",
    "    for value in values:\n",
    "        value_inds = np.nonzero(y==value)[0]\n",
    "        np.random.shuffle(value_inds)\n",
    "        n = int(train_proportion*len(value_inds))\n",
    "\n",
    "        train_inds[value_inds[:n]]=True\n",
    "        test_inds[value_inds[n:]]=True\n",
    "\n",
    "    return train_inds,test_inds\n",
    "\n",
    "\n",
    "train_inds, test_inds = get_train_test_inds(df_full.loc[:, \"target\"])\n",
    "df_full[['target']] = df_full[['target']].astype(int)\n",
    "df = df_full[train_inds]\n",
    "\n",
    "df_val = df_full[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use este trecho no caso de optar por reescalar\"\"\"\n",
    "# df, maximum, minimum = rescale(df, df.columns[0:4])\n",
    "# df_val, _, _ = rescale(df_val, df_val.columns[0:4], maximum, minimum)\n",
    "\n",
    "\"\"\"Use este trecho no caso de optar por normalizar\"\"\"\n",
    "df, mean, std = normalize(df, df.columns[0:2])\n",
    "df_val, _, _ = normalize(df_val, df_val.columns[0:2], mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Função de Ativação Sigmoidal\"\"\"\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação da classe de regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(object):\n",
    "    def __init__(self, input_size, learning_rate=1e-1, sigma=1, weight_decay=0.01):\n",
    "        self.weight_decay = weight_decay\n",
    "        self.sigma = sigma\n",
    "        self.learning_rate = learning_rate\n",
    "        self.theta = sigma * np.random.randn(input_size)\n",
    "        self.bias = np.zeros(1)\n",
    "        self.grads = {}\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: entrada da rede neural 10x2 => wheigts (batch_size, numero_de_classes)\n",
    "        retorna as probabilidades de cada classe \n",
    "        \"\"\"\n",
    "        line = x.dot(self.theta.T) + self.bias\n",
    "        activation = sigmoid(line) # 10x1\n",
    "        \n",
    "        return activation\n",
    "       \n",
    "    def backward(self, y):\n",
    "        \"\"\"\n",
    "        y: indices das classes esperadas (batch_size, 1)\n",
    "        retorna o loss e o dicionario de gradientes\n",
    "        \"\"\"\n",
    "        y_hat = predictions # 1x10\n",
    "        N = y.size\n",
    "        \n",
    "        # batch.values => 10x2\n",
    "        # y_hat => 1x10\n",
    "        # y => 1x10\n",
    "        \n",
    "        #update grads\n",
    "        \n",
    "        # weight is clear!!\n",
    "        w_decay = (self.weight_decay / N) * self.theta\n",
    "        self.grads['w'] = (batch.values.T.dot(y_hat - y) / N) + w_decay\n",
    "\n",
    "        # bias is clear!!\n",
    "        self.grads['b'] = ((y_hat - y) * self.bias).mean()\n",
    "\n",
    "        # loss is clear!!\n",
    "        loss_decay = (self.weight_decay / (2 * N)) * np.sum(self.theta ** 2)\n",
    "        loss = -(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)).mean() + loss_decay\n",
    "        \n",
    "        return loss, self.grads\n",
    "        \n",
    "    def optimize(self):\n",
    "        self.bias = self.bias - self.learning_rate*self.grads[\"b\"]\n",
    "        self.theta = self.theta - self.learning_rate*self.grads[\"w\"]\n",
    "        \n",
    "    \n",
    "logreg = LogReg(2, sigma=1, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executar as iterações do Gradiente Descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Alterar estes hiperparametros\"\"\"\n",
    "epochs = 150\n",
    "batch_size = 20\n",
    "\"\"\"\"\"\"\n",
    "\n",
    "\"\"\"Nao alterar abaixo\"\"\"\n",
    "# Cria o grafico e atualiza os pesos\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(8,3))\n",
    "ax1.set_title('Training Loss')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax3.set_title('Validation Accuracy')\n",
    "\n",
    "t = tqdm(range(epochs))\n",
    "\n",
    "losses = []\n",
    "training_accuracy = []\n",
    "accuracy = []\n",
    "\n",
    "drawn, = ax1.plot(np.arange(0), losses, c='r')\n",
    "drawn2, = ax2.plot(np.arange(0), training_accuracy, c='r')\n",
    "drawn3, = ax3.plot(np.arange(0), accuracy, c='r')\n",
    "\n",
    "# Loop de treinamento\n",
    "for e in t:\n",
    "    df = df.sample(frac=1., random_state=SEED)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Loop da epoca\n",
    "    for i in range(0, df.shape[0]-batch_size, batch_size):\n",
    "        total += batch_size\n",
    "        batch = df.iloc[i:(i+batch_size), :]\n",
    "        y = df.iloc[i:(i+batch_size)]\n",
    "        y = y.loc[:, \"target\"]\n",
    "        batch = batch.drop([\"target\"], axis=1)\n",
    "        predictions = logreg.forward(batch.values)\n",
    "        loss, grads = logreg.backward(y)\n",
    "        total_loss += loss\n",
    "        logreg.optimize()\n",
    "        correct += sum(y.values == (predictions > 0.5))\n",
    "    \n",
    "    # Atualiza estatisticas e graficos\n",
    "    training_accuracy.append(correct/total)\n",
    "    losses.append(total_loss)\n",
    "    t.set_description('Loss: %.3f' % total_loss)\n",
    "    drawn.set_data((np.arange(len(losses)), losses))\n",
    "    ax1.relim()\n",
    "    ax1.set_xlim((0, e))\n",
    "    ax1.autoscale_view()\n",
    "    \n",
    "    drawn2.set_data((np.arange(len(training_accuracy)), training_accuracy))\n",
    "    ax2.relim()\n",
    "    ax2.set_xlim((0, e))\n",
    "    ax2.autoscale_view()\n",
    "    #fig.canvas.draw()\n",
    "    \n",
    "    \n",
    "    ### VALIDACAO ###\n",
    "    batch = df_val\n",
    "    y = df_val.loc[:, \"target\"]\n",
    "    batch = batch.drop([\"target\"], axis=1)\n",
    "\n",
    "    predictions = logreg.forward(batch.values)\n",
    "    correct = np.sum(y.values == (predictions > 0.5))\n",
    "    accuracy.append(correct/df_val.shape[0])\n",
    "    \n",
    "    # Atualiza graficos\n",
    "    drawn3.set_data((np.arange(len(accuracy)), accuracy))\n",
    "    ax3.relim()\n",
    "    ax3.set_xlim((0, e))\n",
    "    ax3.autoscale_view()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# É possível analisar a fronteira de decisão do classificador gerado. Este tipo de análise contribui para interpretação do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Nao alterar\"\"\"\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h = .02\n",
    "\n",
    "values = df.values\n",
    "y = df.loc[:, \"target\"]\n",
    "X1 = values[:, 0]\n",
    "X2 = values[:, 1]\n",
    "\n",
    "# Gera pontos interpolados para geracao da fronteira de decisao\n",
    "x1_min, x1_max = X1.min() - .5, X1.max() + .5\n",
    "x2_min, x2_max = X2.min() - .5, X2.max() + .5\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, h),\n",
    "                       np.arange(x2_min, x2_max, h))\n",
    "\n",
    "\n",
    "# Prediz a probabilidade dos pontos\n",
    "points = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "predictions = logreg.forward(points)\n",
    "predictions = predictions.reshape(xx1.shape)\n",
    "\n",
    "# Gera o grafico\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "ax.set_xlim(xx1.min(), xx1.max())\n",
    "ax.set_ylim(xx2.min(), xx2.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title('Decision Boundary')\n",
    "\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "cm = plt.cm.RdBu\n",
    "\n",
    "ax.contourf(xx1, xx2, predictions, cmap=cm, alpha=.8)\n",
    "\n",
    "ax.scatter(X1, X2, c=y, cmap=cm_bright, edgecolors='k')\n",
    "\n",
    "ax.set_xlim(xx1.min(), xx1.max())\n",
    "ax.set_ylim(xx2.min(), xx2.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "ax.set_xlabel(df.columns[0])\n",
    "ax.set_ylabel(df.columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
